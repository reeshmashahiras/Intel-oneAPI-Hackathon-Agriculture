{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlyYKcoWlrhY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "from sklearn.metrics import classification_report , accuracy_score,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing intel ONE API scikit learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUcP5w5zgx4q",
    "outputId": "8d30d353-43fa-42b5-c99a-7fb2cf0e7f4a"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn-intelex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlFmkGqxgpVB",
    "outputId": "a39db1fe-fa74-41b5-f4d3-643c3f09cd57"
   },
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "KM2VLa4eXesH",
    "outputId": "3168d72d-d183-4c15-cd53-c111df33f7df"
   },
   "outputs": [],
   "source": [
    "!pip install modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vgxZ4mgXoKp"
   },
   "outputs": [],
   "source": [
    "import modin.pandas as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mocxHUpPlrhZ"
   },
   "outputs": [],
   "source": [
    "df =pd.read_csv('Crop_recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f0BAq4l7lrhZ",
    "outputId": "63c90709-591f-4f75-bdbc-1236b14c0600"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oplShXylrhZ",
    "outputId": "8bb9f099-cebd-4a7a-aed8-8623ccef3f9c"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lr_OhBjblrhZ"
   },
   "outputs": [],
   "source": [
    "df.columns = ['Nitrogen','Phosphorus','Potassium','Temperature','Humidity','pH','Rainfall','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEcTfOdOlrhZ",
    "outputId": "0888832f-aac6-4b23-a236-6874174f9b42"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HauudtBbZfGg",
    "outputId": "c3acaa0e-a2d3-48dc-f79a-1ffc2050f095"
   },
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NWrV2kB4blTm",
    "outputId": "e1d8f6a6-e870-4b51-cf4e-01e6514b2ccc"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "3WzEqryKco9e",
    "outputId": "8b8bfdf2-cd79-4bf2-b965-b56c2a7c3486"
   },
   "outputs": [],
   "source": [
    "df[\"Label\"].value_counts().plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "o1jAnG8glrha",
    "outputId": "6a00f456-3e6e-46ff-f5cf-9ca704106183"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BrG336tolrha",
    "outputId": "93dca87c-3d7b-4aa0-dbb4-87d7f4e22e9b"
   },
   "outputs": [],
   "source": [
    "plt.style.use('fast')\n",
    "sns.set_palette(\"Set2\")\n",
    "for i in df.columns[:-1]:\n",
    "    fig,ax = plt.subplots(1,3,figsize=(18,4))\n",
    "    sns.histplot(data = df,x=i,kde = True,bins = 20,ax = ax[0])\n",
    "    sns.violinplot(data = df,x = i,ax =ax[1])\n",
    "    sns.boxplot(data = df,x = i,ax =ax[2])\n",
    "    plt.suptitle(f'Visualizing {i}',size =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "J8ZTQhUklrha",
    "outputId": "5bda54c7-4ce4-416e-8ca6-d3c3c381e440"
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(by = 'Label').mean().reset_index()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZw_lNe4lrha",
    "outputId": "acf6afbb-4633-4158-e8ed-79013ae3b26e"
   },
   "outputs": [],
   "source": [
    "for i in grouped.columns[1:]:\n",
    "    print(f'Top 5 Most {i} requiring crops :')\n",
    "    for j,k in grouped.sort_values(by = i,ascending =False)[:5][['Label',i]].values:\n",
    "        print(f'{j}-->{k}')\n",
    "    print(f'********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pgvgjyxlrha",
    "outputId": "fcc9dc16-2ef6-427f-fcd4-44b80713b7e2"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in grouped.columns[1:]:\n",
    "    print(f'Top 5 Least {i} requiring crops:')\n",
    "    print(f'********************************')\n",
    "    for j ,k in grouped.sort_values(by=i)[:5][['Label',i]].values:\n",
    "        print(f'{j} --> {k}')\n",
    "    print(f'********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JbbhT8qarAET",
    "outputId": "fd06795b-9878-41d8-e6ec-9a198edb1fc7"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "LqaYaIPDry40",
    "outputId": "259fbe15-48da-4dd8-eb0f-d7d3a1c753da"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Plot a subset of data using sample()\n",
    "sns.catplot(data=df.sample(n=1000), x=\"Potassium\", y=\"Phosphorus\", hue=\"Label\", kind=\"swarm\")\n",
    "plt.show()\n",
    "\n",
    "# Measure execution time and display\n",
    "print(\"Execution time for swarm plot:\", time.time() - start_time, \"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Plot specific features using pairplot()\n",
    "sns.pairplot(data=df.sample(n=1000), hue='Label', vars=['Nitrogen', 'Phosphorus', 'Potassium'])\n",
    "plt.show()\n",
    "\n",
    "# Measure execution time and display\n",
    "print(\"Execution time for pair plot:\", time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing both numeric and non-numeric data\n",
    "\n",
    "# Option 1: Drop non-numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Option 2: Convert non-numeric columns to numeric format using one-hot encoding\n",
    "# If you have categorical columns that you want to include, you can encode them\n",
    "# numeric_df = pd.get_dummies(df)\n",
    "\n",
    "# Now, plot the correlation matrix heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(numeric_df.corr(), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1C6WSq8UlMl"
   },
   "source": [
    "\n",
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td6gURmXU55K"
   },
   "source": [
    "As observed from our heat map Potassium and Phosphorus has high corelation value of 0.74\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "UdGzDoG8lrhb",
    "outputId": "35d55c1f-c165-4389-87a8-9eb0eed341e1"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "df_pca = pca.fit_transform(df.drop(['Label'],axis =1))\n",
    "df_pca = pd.DataFrame(df_pca)\n",
    "fig = px.scatter(x = df_pca[0],y = df_pca[1],color = df['Label'],title = \"Decomposed Using PCA\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "5zdMDbKElrhb",
    "outputId": "7f495986-ad69-4e57-c25a-69cc7f65dc40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca3=PCA(n_components=3)\n",
    "df_pca3=pca3.fit_transform(df.drop(['Label'],axis=1))\n",
    "df_pca3=pd.DataFrame(df_pca3)\n",
    "fig = px.scatter_3d(x=df_pca3[0],y=df_pca3[1],z=df_pca3[2],color=df['Label'],title=f\"Variance Explained : {pca3.explained_variance_ratio_.sum() * 100}%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "xPT-ofWTlrhb",
    "outputId": "d7f54207-3835-4fc2-ac57-02c67cb21e84"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(x=df['Nitrogen'],y=df['Phosphorus'],color=df['Label'],title=\"Nitrogen VS Phosphorus\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "9ZGo8OSIlrhb",
    "outputId": "9273980d-7d36-412b-c66b-0a1b963302c1"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(x=df['Phosphorus'],y=df['Potassium'],color=df['Label'],title=\"Phosphorus VS Potassium\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TufizQ35lrhc",
    "outputId": "2f083e3b-c7d0-4e7f-b7e6-a99c55b55dc7"
   },
   "outputs": [],
   "source": [
    "names = df['Label'].unique()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "df['Label']=encoder.fit_transform(df['Label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cm__S1holrhc"
   },
   "outputs": [],
   "source": [
    "X=df.drop(['Label'],axis=1)\n",
    "y=df['Label']\n",
    "#Splitting into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,shuffle = True, random_state = 42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ma1RIX1-lrhc",
    "outputId": "675f33b3-e6f0-4615-90a9-a252c6312653"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_train=pd.DataFrame(X_train,columns=X.columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xk6ZKleDlrhc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAv4qAEHrkB1",
    "outputId": "3c2fa1a7-9c0e-4a0a-adb9-cdf3ef6f7906"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bthBG5cy54s",
    "outputId": "2c418710-eb30-40bf-b6d6-e5ffd31b27c1"
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9p1AUH0zILz",
    "outputId": "cba08dc1-a051-48a3-f8b1-c3189fa18640"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSnp_rQ9lrhc"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from xgboost import XGBClassifier\n",
    "#import lightgbm as lgb\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import other necessary classifiers\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'NuSVC': NuSVC(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Bagging': BaggingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Extra Trees': ExtraTreesClassifier(),\n",
    "    'CatBoost': CatBoostClassifier()\n",
    "\n",
    "}\n",
    "\n",
    "# Fit models and evaluate accuracy\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    np.random.seed(42)\n",
    "    model_scores = {}\n",
    "    # Create a tqdm progress bar with the total number of models\n",
    "    progress_bar = tqdm(models.items(), desc=\"Fitting and scoring models\", total=len(models))\n",
    "    for name, model in progress_bar:\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Calculate the model score\n",
    "        score = model.score(X_test, y_test)\n",
    "        # Store the model score\n",
    "        model_scores[name] = score\n",
    "        # Update the progress bar description\n",
    "        progress_bar.set_postfix({\"Current model\": name, \"Score\": score})\n",
    "    return model_scores\n",
    "\n",
    "# Usage\n",
    "model_scores = fit_and_score(models, X_train, X_test, y_train, y_test)\n",
    "print(model_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKMc94AetaBq",
    "outputId": "0fa494d7-956f-4241-8f7f-a0ca7e4c194e"
   },
   "outputs": [],
   "source": [
    "type(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A53FaQLrlrhd"
   },
   "outputs": [],
   "source": [
    "models = {'Logistic Regression': LogisticRegression(),\n",
    "         'Random Forest': RandomForestClassifier(),\n",
    "         'Tree': DecisionTreeClassifier(),\n",
    "         \"SVC\": SVC(),\n",
    "          \"Linear SVC\":LinearSVC(C=2),\n",
    "          \"NU SVC\":NuSVC(),\n",
    "         \"XGBoost\": XGBClassifier(),\n",
    "         \"KNN\":KNeighborsClassifier(n_neighbors = 5, p=2),\n",
    "          #\"Light GBM\": lgb.LGBMClassifier(),\n",
    "          \"LDA\":LinearDiscriminantAnalysis(),\n",
    "          \"Gaussian NB\":GaussianNB(),\n",
    "          \"AdaBoost\":AdaBoostClassifier(),\n",
    "          \"Gradient Boosting\":GradientBoostingClassifier(),\n",
    "          \"Bagging\":BaggingClassifier(),\n",
    "          \"Extra Trees\":ExtraTreesClassifier(),\n",
    "          \"Cat Boost\":CatBoostClassifier(verbose=False)}\n",
    "\n",
    "def fit_and_score(models,X_train,X_test,y_train,y_test):\n",
    "    np.random.seed(42)\n",
    "    model_scores = {}\n",
    "    for name,model in models.items():\n",
    "        model.fit(X_train,y_train)\n",
    "        model_scores[name] = model.score(X_test,y_test)\n",
    "\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hu-N1CDVtYCa"
   },
   "outputs": [],
   "source": [
    "def plot_dict_as_bar(dict_data, title=None):\n",
    "    keys = list(dict_data.keys())\n",
    "    values = list(dict_data.values())\n",
    "\n",
    "    plt.bar(keys, values)\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    # Rotate x-axis labels by 45 degrees for better alignment\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()  # Adjusts the layout to prevent overlapping\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict_as_bar(model_scores, title='Bar Plot'):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Extract model names and scores\n",
    "    model_names = list(model_scores.keys())\n",
    "    scores = list(model_scores.values())\n",
    "\n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_names, scores, color='skyblue')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim(0, 1)  # Adjust the y-axis limits if needed\n",
    "    plt.show()\n",
    "\n",
    "# Check if all models are included in the model_scores dictionary\n",
    "print(\"Model Scores:\", model_scores)\n",
    "\n",
    "# Plot the bar chart\n",
    "plot_dict_as_bar(model_scores, title='Bar Plot of Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_and_score(models,X_train,X_test,y_train,y_test):\n",
    "    np.random.seed(42)\n",
    "    for name,model in models.items():\n",
    "        print('**************   '+ name + '   ***********')\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        Acc = accuracy_score(y_pred,y_test)\n",
    "        cm = confusion_matrix(y_test,y_pred,labels = [0,1])\n",
    "        print('Confusion Matrix')\n",
    "        sns.heatmap(cm,cmap = 'Greens',annot = True,cbar_kws = {'orientation':'horizontal'})\n",
    "        plt.show()\n",
    "\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        print('.:.'+ name +' Accuracy'+'\\033[1m {:.3f}%'.format(Acc*100)+' .:.')\n",
    "        print('      ')\n",
    "        print('      ')\n",
    "        print('      ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {'Logistic Regression': LogisticRegression(),\n",
    "          'Random Forest': RandomForestClassifier(),\n",
    "          'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "          'SVC': SVC(),\n",
    "          'Linear SVC': LinearSVC(),  # Include LinearSVC in the models\n",
    "          'XGBoost': XGBClassifier(),\n",
    "          'KNN': KNeighborsClassifier(n_neighbors=5, p=2),\n",
    "          'LDA': LinearDiscriminantAnalysis(),\n",
    "          'Gaussian NB': GaussianNB(),\n",
    "          'AdaBoost': AdaBoostClassifier(),\n",
    "          'Gradient Boosting': GradientBoostingClassifier(),\n",
    "          'Bagging': BaggingClassifier(),\n",
    "          'Extra Trees': ExtraTreesClassifier(),\n",
    "          'Cat Boost': CatBoostClassifier(verbose=False)}\n",
    "\n",
    "def cm_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    for name, model in models.items():\n",
    "        print('**************   '+ name + '   ***********')\n",
    "        model.fit(X_train, y_train)  # Fit the model with training data\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, digits=2)\n",
    "        print(report)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "\n",
    "        Acc = model.score(X_test, y_test)\n",
    "        print(f\"{name} Accuracy: {Acc*100:.2f}%\")\n",
    "\n",
    "# Call the cm_and_score function with the models and data\n",
    "cm_and_score(models, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Example of actual and predicted labels\n",
    "y_true = [1, 0, 1, 1, 0]  # Actual labels\n",
    "y_pred = [1, 0, 1, 0, 1]  # Predicted labels\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained models\n",
    "for name, model in models.items():\n",
    "    joblib.dump(model,'model.pkl')\n",
    "\n",
    "# Save the preprocessing steps\n",
    "joblib.dump(le_soil_type, 'soil_type_encoder.pkl')\n",
    "joblib.dump(le_fertilizer_used, 'fertilizer_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained models with unique filenames\n",
    "for name, model in models.items():\n",
    "    filename = f'{name}_model.pkl'  # Unique filename for each model\n",
    "    joblib.dump(model, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
